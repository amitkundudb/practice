{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aab6ba56-7c12-4230-b466-bd71c36355e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\">/**<br /> * Mounts the given source directory into DBFS at the given mount point.<br /> * <br /> * Examples:<br /> *   mount(\"s3n://ACCESS_KEY:SECRET_KEY@my-twitter-bucket/tweets2013/\", \"/mnt/tweets\")<br /> *   ls(\"/mnt/tweets\")<br /> * <br /> *   mount(\"s3n://ACCESS_KEY:SECRET_KEY@my-twitter-bucket/tweets2013/\", \"/mnt/tweets\",<br /> *         \"sse-s3\")<br /> * <br /> * Mount points are persistent -- they will not be lost upon cluster or instance termination.<br /> * The mount point metadata will remain until termination of your Databricks service<br /> * (or until the point is explicitly unmounted). Once a directory is mounted, it can be<br /> * treated like a normal DBFS directory.<br /> * <br /> * Mounting a directory will securely persist any provided credentials, enabling access<br /> * to the data within the mounted directory without having to re-provide credentials.<br /> * It is not possible to access or view the credentials used to support a mount point after<br /> * the mount point is created and the command used to mount the data has been removed. Thus,<br /> * one Databricks user can mount a bucket, delete the mount command and share the data<br /> * with other Databricks users in the same organization, without sharing the security<br /> * credentials with them.<br /> * <br /> * Mounting with encryption is possible. Currently, SSE-S3 and SSE-KMS are supported. Use<br /> * encryptionType = \"sse-s3\" for sse-s3 encryption, \"sse-kms\" for sse-kms encryption with<br /> * default kms master key, and \"sse-kms:key-id\" for sse-kms encryption with separate kms key.<br /> * The source directory will not be mounted if an invalid encryption type is passed in.<br /> * <br /> * Once this method returns, the mount should be accessible from every instance within your<br /> * shard. However, since this information may be cached, you may have to run refreshMounts()<br /> * in a cluster for it to show up. Note that mount() actually runs refreshMounts() on the<br /> * current cluster.<br /> * <br /> * @param source FileSystem URI that contains the source data.<br /> *               This cannot be a DBFS URI.<br /> * @param mountPoint The directory within DBFS to mount the source. This must be within /mnt.<br /> * @param encryptionType Encryption type with which we mount the source. This means every new<br /> *                       object written using this mount will be written with encryption.<br /> * @param owner Deprecated. This parameter is deprecated, please do not set it.<br /> * @param extraConfigs A map containing extra configurations that will be used when<br /> *                     accessing the mount point. For every entry in the map, key<br /> *                     is the config name and the value is the value of the config.<br /> *                     Please only provide configs that are advised by Databricks<br /> *                     documentations.<br /> * @return True if the path was successfully mounted.<br /> */<br /><b>mount(source: java.lang.String, mountPoint: java.lang.String, encryptionType: java.lang.String = \"\", owner: java.lang.String = null, extraConfigs: scala.collection.Map = Map.empty[String, String]): boolean</b></div><br />"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " dbutils.fs.help('mount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60c6ca3d-ee77-4c75-808f-6a0aea50a23a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1368225071648762>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m IIHH\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'IIHH' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "NameError",
        "evalue": "name 'IIHH' is not defined"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'IIHH' is not defined"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-1368225071648762>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m IIHH\n",
        "\u001B[0;31mNameError\u001B[0m: name 'IIHH' is not defined"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " dbutils.fs.mount(source = 'wasps://<containerNmae>@<accountNmae>.blob.core.windows.nest',\n",
    "                  mount_point = '/mnt/<mountName>',\n",
    "                  extra_configs = 'fs.azure.account.key.blobstorage.blob.core.windows.net':'accountkey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d69e32e-8f0e-4ab5-8d6b-305c2fd65245",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Here I have given syntax for mounting as I don't have acces to azure blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c81ce2e-4831-4b35-a77f-44d48e45f20f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# now we can perform everything on our external storage as we perform on dbfs files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46c4c4dc-7174-4042-94a5-d297cd68a904",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delete or unmount Mount Points\n",
    "dbutils.fs.unmount()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "mount",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
